{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3zaxI-OFc7u"
      },
      "outputs": [],
      "source": [
        "#feedfoward on all features+val\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=64, callbacks=[early_stop])\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred_ff = model.predict(X_val)\n",
        "y_pred_ff = np.round(y_pred_ff)\n",
        "print(classification_report(y_val, y_pred_ff))\n",
        "print(confusion_matrix(y_val, y_pred_ff))\n",
        "\n",
        "cm = confusion_matrix(y_val, y_pred_ff)\n",
        "plt.imshow(cm, cmap='binary')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.xticks([0, 1])\n",
        "plt.yticks([0, 1])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "# Plot the learning curve\n",
        "plt.plot(history.history['loss'], label='training loss')\n",
        "plt.plot(history.history['val_loss'], label='validation loss')\n",
        "plt.title('Learning Curve')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Generate accuracy learning curve\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Accuracy Learning Curve')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Plot the ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_val, y_pred_ff)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.plot(fpr, tpr, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ]
}