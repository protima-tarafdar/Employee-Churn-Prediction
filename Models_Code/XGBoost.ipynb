{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-A5p5X0_DiUK"
      },
      "outputs": [],
      "source": [
        "#xgb with all features on validation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "from sklearn.model_selection import learning_curve, cross_val_score, validation_curve, GridSearchCV, train_test_split\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
        "\n",
        "\n",
        "xgb_clf = xgb.XGBClassifier()\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred_xgb = xgb_clf.predict(X_val)\n",
        "\n",
        "print(classification_report(y_val, y_pred_xgb))\n",
        "print(confusion_matrix(y_val, y_pred_xgb))\n",
        "\n",
        "sns.heatmap(confusion_matrix(y_val, y_pred_xgb), annot=True, cmap='Blues')\n",
        "plt.title('Confusion Matrix Heatmap')\n",
        "plt.show()\n",
        "\n",
        "train_sizes, train_scores, test_scores = learning_curve(xgb_clf, X_train, y_train, cv=5, train_sizes=np.linspace(0.1, 1.0, 10))\n",
        "\n",
        "plt.plot(train_sizes, np.mean(train_scores, axis=1), 'o-', color='r', label='Training Score')\n",
        "plt.plot(train_sizes, np.mean(test_scores, axis=1), 'o-', color='g', label='Cross-Validation Score')\n",
        "plt.xlabel('Training Examples')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Learning Curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "\n",
        "xgb_acc_all = accuracy_score(y_val, y_pred_xgb)\n",
        "xgb_f1_all = f1_score(y_val, y_pred_xgb)\n",
        "xgb_precision_all = precision_score(y_val, y_pred_xgb)\n",
        "xgb_recall_all = recall_score(y_val, y_pred_xgb)\n",
        "xgb_auc_all = roc_auc_score(y_val, y_pred_xgb)\n",
        "\n",
        "y_prob = xgb_clf.predict_proba(X_val)[:, 1]\n",
        "fpr, tpr, thresholds = roc_curve(y_val, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.plot(fpr, tpr, color='b', label='ROC Curve (AUC = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--', label='Random Guess')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.0])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ]
}