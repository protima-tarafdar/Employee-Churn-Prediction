{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mit0C8-6H9b5"
      },
      "outputs": [],
      "source": [
        "#On all features with validation set\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# define the KNN model\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_neighbors': [5, 10, 15],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan']\n",
        "}\n",
        "\n",
        "# define the GridSearchCV object with 5-fold cross validation\n",
        "grid_search_knn = GridSearchCV(knn, param_grid, cv=5, scoring='f1')\n",
        "\n",
        "# fit the GridSearchCV object to the data\n",
        "grid_search_knn.fit(X_train, y_train)\n",
        "\n",
        "# get the best estimator and its hyperparameters\n",
        "best_knn = grid_search_knn.best_estimator_\n",
        "print('Best hyperparameters:', grid_search_knn.best_params_)\n",
        "\n",
        "# predict on the test set using the best estimator\n",
        "y_pred_knn = best_knn.predict(X_val)\n",
        "\n",
        "# get the classification report and confusion matrix\n",
        "print(classification_report(y_val, y_pred_knn))\n",
        "print(confusion_matrix(y_val, y_pred_knn))\n",
        "\n",
        "conf_matrix = confusion_matrix(y_val, y_pred_knn)\n",
        "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_val, best_knn.predict_proba(X_val)[:,1])\n",
        "auc = roc_auc_score(y_val, best_knn.predict_proba(X_val)[:,1])\n",
        "plt.plot(fpr, tpr, label=f'AUC = {auc:.3f}')\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "train_sizes, train_scores, test_scores = learning_curve(best_knn, X_train, y_train, cv=5, scoring='f1', n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 10))\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "test_mean = np.mean(test_scores, axis=1)\n",
        "test_std = np.std(test_scores, axis=1)\n",
        "plt.plot(train_sizes, train_mean, label='Training score')\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.2)\n",
        "plt.plot(train_sizes, test_mean, label='Cross-validation score')\n",
        "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.2)\n",
        "plt.xlabel('Number of training examples')\n",
        "plt.ylabel('F1 score')\n",
        "plt.title('Learning Curve')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "precision, recall, thresholds = precision_recall_curve(y_val, best_knn.predict_proba(X_val)[:,1])\n",
        "plt.plot(recall, precision, label=f'AP = {average_precision:.3f}')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ]
}